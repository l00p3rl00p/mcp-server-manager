import os
import json
import sqlite3
import subprocess
import sys
import shlex
import datetime
from flask import Flask, jsonify, request, send_from_directory
from flask_cors import CORS
from collections import deque
import time

METRIC_HISTORY = deque(maxlen=60)
from pathlib import Path

# Determine the directory where this script lives
BASE_DIR = Path(__file__).parent.resolve()

app = Flask(__name__, static_folder=str(BASE_DIR / "gui" / "dist"), static_url_path="")
CORS(app, origins=["http://localhost:5173", "http://127.0.0.1:5173", "http://localhost:5174", "http://localhost:5001", "http://127.0.0.1:5001"])

@app.route("/")
def serve_index():
    """Serve the built React frontend's index.html."""
    return send_from_directory(app.static_folder, "index.html")

@app.route("/<path:path>")
def serve_static(path):
    """Serve assets and other static files from gui/dist."""
    # Check if the requested path exists in static_folder
    if path != "" and os.path.exists(os.path.join(app.static_folder, path)):
        return send_from_directory(app.static_folder, path)
    # Default to index.html for React Router compatibility
    return send_from_directory(app.static_folder, "index.html")

# Official Logging Integration
try:
    sys.path.insert(0, str(Path(__file__).parent.parent / "mcp-link-library"))
    from nexus_session_logger import NexusSessionLogger
    session_logger = NexusSessionLogger()
except:
    session_logger = None

# Base Discovery
NEXUS_HOME = Path.home() / ".mcp-tools"
PROJECTS_FILE = Path.home() / ".mcpinv" / "projects.json"
ACTIVE_CONTEXT_FILE = Path.home() / ".mcpinv" / "active_context.json"

class ProjectManager:
    def __init__(self):
        self.active_project = None
        self.app_data_dir = NEXUS_HOME / "mcp-server-manager"
        self.inventory_path = self.app_data_dir / "inventory.yaml"
        self.log_path = Path.home() / ".mcpinv" / "session.jsonl"
        self.bin_dir = NEXUS_HOME / "bin"
        self.watcher_proc = None # Track the PID
        self.acknowledged_errors = 0.0 # Timestamp of last error clear
        self.last_forge_result = None # Persist the last successful forge
        self.load_active_context()
        self.ensure_core_services()

    def ensure_core_services(self):
        """Auto-starts Type-0 Core Dependencies (Librarian) if not running."""
        try:
            import psutil
            # Check for Librarian
            librarian_running = False
            for p in psutil.process_iter(['name', 'cmdline']):
                try:
                    cmd = ' '.join(p.info['cmdline'] or [])
                    if "nexus-librarian" in cmd or "mcp-librarian" in cmd:
                        librarian_running = True
                        break
                except: pass
            
            if not librarian_running:
                librarian_bin = self.bin_dir / "mcp-librarian"
                if librarian_bin.exists():
                    if session_logger: 
                        session_logger.log("LIFECYCLE", "Auto-Starting Core Service: Librarian", suggestion="Core dependency missing.")
                    # Launch detached
                    subprocess.Popen([str(librarian_bin)], start_new_session=True)
                else:
                    if session_logger:
                        session_logger.log("ERROR", "Core Service Missing: mcp-librarian binary not found.")
        except Exception as e:
            if session_logger: session_logger.log("ERROR", f"Core Service Auto-Start Failed: {e}")

    def load_active_context(self):
        """Restores the last active project and session state (like acknowledged errors)."""
        if ACTIVE_CONTEXT_FILE.exists():
            try:
                with open(ACTIVE_CONTEXT_FILE, 'r') as f:
                    ctx = json.load(f)
                    self.acknowledged_errors = ctx.get("acknowledged_errors", 0.0)
                    self.last_forge_result = ctx.get("last_forge_result")
                    self.set_project(ctx.get("path"), ctx.get("id"), reset_ack=False)
            except: pass
        if not self.active_project:
            self.set_project(str(self.app_data_dir), "nexus-default")

    def save_snapshot(self):
        """Captures a timestamped copy of the inventory.yaml for recovery."""
        if not self.inventory_path.exists(): return
        try:
            # Ensure snapshot directory exists
            snapshot_dir = self.app_data_dir / "snapshots"
            snapshot_dir.mkdir(parents=True, exist_ok=True)
            
            # Create timestamped filename
            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            target_file = snapshot_dir / f"inventory_{stamp}.yaml"
            
            # Copy file
            import shutil
            shutil.copy2(self.inventory_path, target_file)
            
            # Prune old snapshots (keep last 10)
            snaps = sorted(snapshot_dir.glob("inventory_*.yaml"))
            while len(snaps) > 10:
                oldest = snaps.pop(0)
                try: oldest.unlink()
                except: pass
        except Exception as e:
            if session_logger: session_logger.log("ERROR", f"Snapshot capture failed: {str(e)}")

    def set_project(self, path: str, p_id: str, reset_ack: bool = True):
        """Standardizes paths for a specific project context and saves the active session."""
        path = Path(path)
        self.active_project = {"id": p_id, "path": str(path)}
        # Project-specific paths
        self.app_data_dir = path
        self.inventory_path = path / "inventory.yaml"
        
        # Reset acknowledged errors when switching projects so history is fresh
        if reset_ack:
            self.acknowledged_errors = 0.0
            
        self.save_context()

    def save_context(self):
        """Saves current project and session markers."""
        ACTIVE_CONTEXT_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(ACTIVE_CONTEXT_FILE, 'w') as f:
            json.dump({
                **self.active_project,
                "acknowledged_errors": self.acknowledged_errors,
                "last_forge_result": self.last_forge_result
            }, f)

    def get_projects(self):
        if not PROJECTS_FILE.exists():
            projects = [{"id": "nexus-default", "name": "Workforce Nexus (Default)", "path": str(NEXUS_HOME / "mcp-server-manager")}]
            with open(PROJECTS_FILE, 'w') as f: json.dump(projects, f)
        
        with open(PROJECTS_FILE, 'r') as f:
            return json.load(f)

    def get_inventory(self):
        import yaml
        if not self.inventory_path.exists(): return {"servers": []}
        try:
            with open(self.inventory_path, 'r') as f:
                return yaml.safe_load(f) or {"servers": []}
        except: return {"servers": []}

pm = ProjectManager()

@app.route('/health', methods=['GET'])
def health():
    """Returns the basic health status and active project context."""
    return jsonify({"status": "ok", "project": pm.active_project})

@app.route('/logs', methods=['GET'])
def get_logs():
    """Retrieves the last 100 log entries from the session log file."""
    if not pm.log_path.exists(): return jsonify([])
    logs = []
    try:
        with open(pm.log_path, "r", encoding="utf-8") as f:
            lines = f.readlines()[-100:]
            for line in lines:
                try: logs.append(json.loads(line))
                except Exception as e:
                    if session_logger: session_logger.log("ERROR", f"Log line corruption: {str(e)}")
                    continue
        return jsonify(logs)
    except Exception as e: return jsonify({"error": str(e)}), 500

@app.route('/status', methods=['GET'])
def get_status():
    """
    Compiles a comprehensive system status report including:
    - Process liveness check (Librarian, Bridge, Servers)
    - Resource usage metrics (CPU, RAM, PID)
    - MCP Server inventory status
    """
    import psutil
    import yaml
    
    servers = []
    # Capture PID, Name, Cmdline
    procs = list(psutil.process_iter(['name', 'cmdline', 'pid']))
    
    def find_process(patterns):
        for p in procs:
            try:
                cmdline = ' '.join(p.info['cmdline'] or [])
                if any(pat in cmdline for pat in patterns): return p
            except Exception as e:
                # Silently ignore 404/connection errors for pings to avoid log bloat, but log system exceptions
                pass
        return None

    librarian_proc = find_process(["mcp.py", "nexus-librarian"])
    librarian_online = librarian_proc is not None
    core_keywords = ["mcp-injector", "mcp-server-manager", "repo-mcp-packager", "nexus-librarian"]

    if pm.inventory_path.exists():
        try:
            with open(pm.inventory_path, "r") as f:
                data = yaml.safe_load(f)
                for s_data in data.get("servers", []):
                    s_id = s_data.get("id")
                    run_config = s_data.get("run", {})
                    start_cmd = run_config.get("start_cmd", "")
                    
                    proc = None
                    if "mcp.py" in start_cmd or "librarian" in s_id: proc = librarian_proc
                    elif "gui_bridge.py" in start_cmd:
                        # Self-identification
                        proc = psutil.Process(os.getpid())
                    elif start_cmd:
                        parts = [p for p in start_cmd.split() if len(p) > 3 and not p.startswith('-')]
                        proc = find_process(parts)

                    online = proc is not None
                    
                    # Detailed Metrics
                    stats = {"cpu": 0, "ram": 0, "pid": None}
                    if online:
                        try:
                            # Use oneshot to avoid race conditions
                            with proc.oneshot():
                                stats["cpu"] = proc.cpu_percent(interval=None)
                                stats["ram"] = proc.memory_info().rss  # Bytes
                                stats["pid"] = proc.pid
                        except: pass

                    is_core = any(k in s_id for k in core_keywords)
                    servers.append({
                        "id": s_id, "name": s_data.get("name", s_id),
                        "status": "online" if online else "stopped",
                        "type": "core" if is_core else run_config.get("kind", "generic"),
                        "metrics": stats,
                        "raw": s_data
                    })
        except Exception as e:
            if session_logger: session_logger.log("ERROR", f"Inventory sync failed: {str(e)}")
            pass

    # Global Metrics
    d = psutil.disk_usage('/')
    current_metrics = {
        "cpu": psutil.cpu_percent(interval=None),
        "memory": psutil.virtual_memory().percent,
        "ram_total": psutil.virtual_memory().total,
        "ram_used": psutil.virtual_memory().used,
        "disk": d.percent,
        "disk_total": d.total,
        "disk_used": d.used,
        "disk_free": d.free,
        "ts": time.time()
    }
    
    METRIC_HISTORY.append(current_metrics)

    resource_count = 0
    db_path = pm.app_data_dir / "knowledge.db"
    if db_path.exists():
        try:
            conn = sqlite3.connect(db_path)
            resource_count = conn.execute("SELECT count(*) FROM links").fetchone()[0]
            conn.close()
        except Exception as e:
            if session_logger: session_logger.log("ERROR", f"Project history fetch failed: {str(e)}")
            pass

    # Version Status
    version_status = "up-to-date"
    try:
        activator_path = pm.bin_dir / "mcp-activator"
        if activator_path.exists():
            mtime = activator_path.stat().st_mtime
            if (datetime.datetime.now().timestamp() - mtime) > 86400:
                version_status = "sync-required"
    except: pass

    missing_cores = []
    if not (pm.bin_dir / "mcp-activator").exists(): missing_cores.append("activator")
    if not librarian_online: missing_cores.append("librarian")

    if missing_cores:
        pulse = "red"; posture = f"Degraded: Missing {', '.join(missing_cores)}"
    elif current_metrics["cpu"] > 80:
        pulse = "yellow"; posture = "Resource Pressure"
    else:
        pulse = "green"; posture = "Optimal"

    return jsonify({
        "activator": "online" if (pm.bin_dir / "mcp-activator").exists() else "missing",
        "librarian": "online" if librarian_online else "stopped",
        "version_status": version_status,
        "posture": posture,
        "pulse": pulse,
        "metrics": current_metrics,
        "history": list(METRIC_HISTORY),
        "servers": servers,
        "resource_count": resource_count,
        "active_project": pm.active_project
    })

@app.route('/validate', methods=['GET'])
def validate_env():
    """Deep environment validation with ranked fixes."""
    results = []
    
    # 1. Critical: Scan session logic for recent errors
    try:
        log_path = pm.log_path
        if log_path.exists():
            with open(log_path, "r") as f:
                # Read last 50 lines for better coverage
                lines = f.readlines()
                recent_errors = []
                for line in lines[-50:]:
                    try:
                        entry = json.loads(line)
                        # Only show errors that haven't been acknowledged
                        if entry.get("level") == "ERROR" and entry.get("timestamp", 0) > pm.acknowledged_errors:
                            recent_errors.append(entry)
                    except: pass
                
                if recent_errors:
                    # Group by message to avoid spam
                    unique_msgs = set([e.get("message") for e in recent_errors])
                    for msg in unique_msgs:
                        results.append({
                            "domain": "Runtime", 
                            "status": "error", 
                            "msg": f"Last Error: {msg}", 
                            "fix": "Re-run command with --debug"
                        })
    except Exception as e:
        print(f"Validator error: {e}")

    # 2. Check Server Health
    try:
        inventory = pm.get_inventory()
        for server_id, cfg in inventory.get("mcp_servers", {}).items():
            # Basic process check if possible
            pass
    except: pass

    # 3. Check Python version
    if sys.version_info < (3, 10):
        results.append({"domain": "Python", "status": "warning", "msg": "Python 3.10+ recommended.", "fix": "Upgrade Python"})
    
    # 2. Check BIN_DIR existence
    if not pm.bin_dir.exists():
        results.append({"domain": "Infrastructure", "status": "fatal", "msg": "Hardened binaries missing.", "fix": "mcp-activator --sync"})
    
    # 3. Check writable paths
    for p in [pm.app_data_dir, pm.log_path.parent]:
        if p.exists() and not os.access(p, os.W_OK):
            results.append({"domain": "Permissions", "status": "fatal", "msg": f"Cannot write to {p}", "fix": f"chmod +w {p}"})

    # 4. Check for critical artifacts
    if not (pm.app_data_dir / "knowledge.db").exists():
        results.append({"domain": "Librarian", "status": "warning", "msg": "Knowledge base empty.", "fix": "Add scan roots and index"})

    # 5. Check for common port conflicts - REMOVED (self-check causes false positive)
    # import socket
    # def is_port_in_use(port):
    #     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
    #         return s.connect_ex(('localhost', port)) == 0
    # if is_port_in_use(5001):
    #     results.append({"domain": "Networking", "status": "warning", "msg": "Port 5001 in use (Bridge default).", "fix": "Check for other bridge instances"})

    return jsonify(results)

@app.route('/nexus/acknowledge', methods=['GET', 'POST', 'OPTIONS'])
def acknowledge_errors():
    """Silence current error notifications in the GUI."""
    pm.acknowledged_errors = time.time()
    pm.save_context() # RED TEAM: Persist dismissal
    if session_logger:
        session_logger.log("INFO", "GUI Error Notifications Cleared", suggestion="Logs remain accessible in the Terminal tab.")
    return jsonify({"success": True, "ts": pm.acknowledged_errors})

@app.route('/nexus/run', methods=['POST'])
def nexus_run_command():
    cmd_str = request.json.get("command")
    if not cmd_str: return jsonify({"error": "Command required"}), 400
    allowed_bins = ["mcp-activator", "mcp-observer", "mcp-librarian", "mcp-surgeon", "python3", "npx"] # Allow python3 for injector
    cmd_base = cmd_str.split()[0]
    if cmd_base not in allowed_bins:
        return jsonify({"error": f"Command '{cmd_base}' not allowed"}), 403

    try:
        # Use system command if not found in bin_dir
        binary_path = pm.bin_dir / cmd_base
        if not binary_path.exists():
            binary_path = cmd_base # Fallback to PATH for system commands
        
        # SPECIAL HANDLING: mcp-surgeon needs strict argument parsing
        # The frontend sends "mcp-surgeon --add foo --client claude"
        # We must ensure this splits into ["--add", "foo", "--client", "claude"]
        if cmd_base == "mcp-surgeon":
             # Use whitespace splitting for flags, but respect quotes if any
             # Re-construct the clean list without the binary name
             args = shlex.split(cmd_str)[1:]
             # Patch: Specifically check for --add and ensure proper flag separation
             # If cmd_str is "mcp-surgeon --add notebooklm --client google-antigravity"
             # args should be ['--add', 'notebooklm', '--client', 'google-antigravity']
             # The previous logic relying on split() might have failed if shlex wrapped things strangely
             pass # shlex.split usually handles this correct, but let's be explicit if needed
        else:
             args = shlex.split(cmd_str)[1:]
        # v11: Pass project context via env if needed
        env = os.environ.copy()
        env["NEXUS_PROJECT_PATH"] = pm.active_project["path"]
        result = subprocess.run([str(binary_path)] + args, capture_output=True, text=True, timeout=30, env=env)
        
        if session_logger:
            status = "SUCCESS" if result.returncode == 0 else "FAILED"
            # Log with full stdout/stderr in metadata
            session_logger.log_command(
                cmd_str, 
                status, 
                result=result.stdout if result.returncode == 0 else result.stderr
            )

        return jsonify({"success": result.returncode == 0, "stdout": result.stdout, "stderr": result.stderr})
    except Exception as e: 
        if session_logger:
            session_logger.log("ERROR", f"Command execution failed: {cmd_str}", metadata={"error": str(e)})
        return jsonify({"error": str(e)}), 500

@app.route('/llm/batch', methods=['POST'])
def llm_batch_process():
    """
    Sub-Agent Supervisor: Executes multiple LLM extractions in parallel.
    Reduces total token round-trips by aggregating results on the server.
    """
    requests_data = request.json.get("requests", [])
    if not requests_data: return jsonify({"error": "No requests provided"}), 400
    
    from concurrent.futures import ThreadPoolExecutor
    
    import sys
    from pathlib import Path
    lib_path = str(Path(__file__).parent.parent / "mcp-link-library")
    if lib_path not in sys.path: sys.path.append(lib_path)
    try:
        from mcp_wrapper import wrapper
    except ImportError:
        return jsonify({"error": "MCPWrapper not found"}), 500
    # Real parallel loop

    with ThreadPoolExecutor(max_workers=5) as executor:
        results = list(executor.map(wrapper.call, requests_data))
        
    return jsonify({
        "total": len(results),
        "results": results,
        "efficiency_gain": "PARALLEL_REAL_EXECUTION"
    })

@app.route('/mcp/sse', methods=['GET'])
def mcp_sse():
    """Server-Sent Events endpoint for MCP clients."""
    from flask import Response
    def event_stream():
        # Instructions for the web client
        yield f"data: {json.dumps({'type': 'info', 'msg': 'Nexus Librarian SSE Connected'})}\n\n"
        while True:
            # We would normally wait for actual MCP events here
            # For now, keep connection alive
            import time
            time.sleep(15)
            yield f"data: {json.dumps({'type': 'ping'})}\n\n"
    return Response(event_stream(), mimetype="text/event-stream")

@app.route('/export/report', methods=['GET'])
def export_report():
    """Generate a high-fidelity HTML report."""
    from flask import render_template_string
    template = """
    <html>
    <head><style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; padding: 40px; color: #333; background: #f4f4f9; }
        .card { background: white; border: 1px solid #ddd; padding: 25px; border-radius: 12px; margin-bottom: 25px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
        h1 { color: #2c3e50; }
        h2 { color: #34495e; border-bottom: 2px solid #eee; padding-bottom: 10px; }
        .success { color: #2ecc71; font-weight: bold; }
        .error { color: #e74c3c; font-weight: bold; }
        .warning { color: #f1c40f; font-weight: bold; }
        table { width: 100%; border-collapse: collapse; margin-top: 15px; }
        th, td { text-align: left; padding: 12px; border-bottom: 1px solid #eee; }
        th { background: #f8f9fa; color: #7f8c8d; font-size: 12px; text-transform: uppercase; }
        code { background: #f1f2f6; padding: 2px 6px; border-radius: 4px; font-family: monospace; color: #e74c3c; }
        .log-entry { font-family: monospace; font-size: 12px; border-bottom: 1px solid #eee; padding: 8px 0; }
    </style></head>
    <body>
        <h1>Nexus Audit Report</h1>
        <p><strong>Generated:</strong> {{ time }}</p>
        
        <div class="card">
            <h2>System Health</h2>
            <p><strong>Overall Posture:</strong> <span class="{{ 'success' if status.pulse == 'green' else 'error' }}">{{ status.posture }}</span></p>
            <p><strong>Project:</strong> {{ project.id }}</p>
            <p><strong>Location:</strong> <code>{{ project.path }}</code></p>
            
            <table>
                <tr><th>Component</th><th>Status</th></tr>
                <tr><td>Activator</td><td class="{{ 'success' if status.activator == 'online' else 'error' }}">{{ status.activator }}</td></tr>
                <tr><td>Librarian</td><td class="{{ 'success' if status.librarian == 'online' else 'error' }}">{{ status.librarian }}</td></tr>
            </table>
        </div>

        <div class="card">
            <h2>Inventory Manifest</h2>
            <table>
                <thead>
                    <tr><th>ID</th><th>Status</th><th>Type</th><th>PID</th></tr>
                </thead>
                <tbody>
                    {% for s in status.servers %}
                    <tr>
                        <td>{{ s.name }}</td>
                        <td><span class="{{ 'success' if s.status == 'online' else 'error' }}">{{ s.status }}</span></td>
                        <td>{{ s.type }}</td>
                        <td>{{ s.metrics.pid or '-' }}</td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
        </div>

        <div class="card">
            <h2>Recent Activity Logs</h2>
            {% for log in logs[-20:] %}
            <div class="log-entry">
                <span style="color: #95a5a6">{{ log.iso }}</span>
                <span style="font-weight: bold; color: {{ '#e74c3c' if log.level == 'ERROR' else '#3498db' }}">{{ log.level }}</span>
                {{ log.message }}
            </div>
            {% endfor %}
        </div>
    </body>
    </html>
    """
    
    # Gather data
    status_data = get_status().get_json()
    logs_data = get_logs().get_json()
    
    html = render_template_string(template, 
                                  time=datetime.datetime.now().isoformat(),
                                  project=pm.active_project,
                                  status=status_data,
                                  logs=logs_data)
    return html

@app.route('/nexus/catalog', methods=['GET'])
def nexus_catalog():
    """Return a metadata catalog of all reachable Nexus commands."""
    catalog = [
        {
            "id": "observer",
            "name": "Nexus Observer",
            "bin": "mcp-observer",
            "description": "Health Monitoring and Resource Telemetry.",
            "actions": [
                {"name": "Health Check",  "cmd": "health",   "desc": "Active probe of system components."},
                {"name": "List Servers",  "cmd": "list",     "desc": "Show all registered MCP servers."},
                {"name": "Running Procs", "cmd": "running",  "desc": "Check running server processes."},
                {"name": "Custom Run",    "cmd": "",         "desc": "Run observer with custom flags (e.g. --verbose, --export)."}
            ]
        },
        {
            "id": "activator",
            "name": "Nexus Activator",
            "bin": "mcp-activator",
            "description": "Installer and synchronization engine.",
            "actions": [
                {"name": "Sync Suite",    "cmd": "--sync",   "desc": "Updates all Nexus components to match local source."},
                {"name": "Repair Suite",  "cmd": "--repair", "desc": "Fixes missing dependencies and permissions."},
                {"name": "Custom Run",    "cmd": "",         "desc": "Run activator with custom flags (e.g. --lite, --permanent)."}
            ]
        },
        {
            "id": "librarian",
            "name": "Nexus Librarian",
            "bin": "mcp-librarian",
            "description": "Knowledge Base and Resource Manager.",
            "actions": [
                {"name": "Index Suite",    "cmd": "--index-suite", "desc": "Scan Observer/Injector for discovery."},
                {"name": "Add Resource",   "cmd": "--add",         "desc": "Index a new URL.", "arg": "url"},
                {"name": "Start Watcher",  "cmd": "--watch",       "desc": "Activate real-time file monitoring."},
                {"name": "Custom Run",     "cmd": "",              "desc": "Run librarian with custom flags (e.g. --search, --prune)."}
            ]
        },
        {
            "id": "injector",
            "name": "MCP Injector (Surgeon)",
            "bin": "mcp-surgeon",
            "description": "Output management for IDE configurations.",
            "actions": [
                {"name": "List Clients",   "cmd": "--list-clients", "desc": "Show locations of detected IDE configs."},
                {"name": "List Detected",  "cmd": "--list-clients", "desc": "[Requires Client] Use Custom Run for --list."},
                {"name": "Custom Run",     "cmd": "",               "desc": "Run injector with custom flags (e.g. --client claude --list)."}
            ]
        }
    ]
    return jsonify(catalog)

@app.route('/injector/clients', methods=['GET'])
def injector_clients():
    """Returns a list of installed/detected MCP clients (IDEs)."""
    clients = []
    try:
        cmd = [str(pm.bin_dir / "mcp-surgeon"), "--list-clients"]
        res = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
        if res.returncode == 0:
            # Parse output: "✅ CLIENT_NAME"
            for line in res.stdout.splitlines():
                if "✅" in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        # parts[0] is emoji, parts[1] is name
                        clients.append(parts[1].lower())
    except Exception as e:
        if session_logger: session_logger.log("ERROR", f"Client detection failed: {e}")
    
    return jsonify({"clients": clients})

@app.route('/injector/status', methods=['POST'])
def injector_status():
    """
    Checks where a specific server is currently injected.
    It scrapes `mcp-surgeon --list-clients` then checks individual configs.
    NOTE: Ideally this should leverage mcp-surgeon internal API, but running CLI is safer for now.
    """
    target_name = request.json.get("name")
    if not target_name: return jsonify({"error": "Name required"}), 400
    
    injected_into = []
    
    # 1. Get detected clients dynamically
    clients = []
    try:
        cmd = [str(pm.bin_dir / "mcp-surgeon"), "--list-clients"]
        res = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
        if res.returncode == 0:
             for line in res.stdout.splitlines():
                if "✅" in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        clients.append(parts[1].lower())
    except:
        # Fallback if detection fails
        clients = ["claude", "vscode", "cursor", "windsurf"]

    try:
        for c in clients:
            # We run listing for each client.
            check_cmd = [str(pm.bin_dir / "mcp-surgeon"), "--client", c, "--list"]
            # Allow failure if client not found
            res = subprocess.run(check_cmd, capture_output=True, text=True, timeout=5)
            if res.returncode == 0:
                # Surgeon outputs "  - name: my-server" or similar
                if f"name: {target_name}" in res.stdout.lower() or f"- {target_name}" in res.stdout.lower():
                    injected_into.append(c)
    except Exception as e:
        if session_logger: session_logger.log("ERROR", f"Injection check failed: {e}")

    return jsonify({"server": target_name, "injected_into": injected_into})

@app.route('/project/history', methods=['GET'])
def project_history():
    """Returns a list of available system state snapshots."""
    snapshot_dir = pm.app_data_dir / "snapshots"
    if not snapshot_dir.exists(): return jsonify([])
    snaps = sorted(snapshot_dir.glob("inventory_*.yaml"), reverse=True)
    return jsonify([{"name": s.name, "path": str(s), "time": s.stat().st_mtime} for s in snaps])

@app.route('/system/update/nexus', methods=['POST'])
def system_update_nexus():
    """Update the Nexus Suite (git pull + reinstall)."""
    try:
        # Assumes running from source
        root = pm.app_data_dir.parent # strict assumption, usage varies
        # Better: use the current working directory if it's a git repo
        repo_dir = Path.cwd()
        if (repo_dir / ".git").exists():
             subprocess.Popen(["git", "pull"], cwd=repo_dir, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
             # We might need to restart the bridge?
             return jsonify({"success": True, "message": "Git pull initiated. Please restart the bridge to apply changes."})
        return jsonify({"error": "Not a git repository."}), 400
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/nexus/help', methods=['POST'])
def nexus_help():
    """Fetches help output for a given binary."""
    bin_str = request.json.get("bin")
    if not bin_str: return jsonify({"error": "Binary required"}), 400
    
    allowed = ["mcp-activator", "mcp-observer", "mcp-librarian", "python3"]
    cmd_parts = shlex.split(bin_str)
    if cmd_parts[0] not in allowed:
         return jsonify({"error": "Command not allowed"}), 403
         
    try:
        # Append --help. Handle python scripts correctly by appending to the end.
        full_cmd = cmd_parts + ["--help"]
        env = os.environ.copy()
        env["NEXUS_PROJECT_PATH"] = pm.active_project["path"]
        
        res = subprocess.run(full_cmd, capture_output=True, text=True, timeout=5, env=env)
        output = res.stdout if res.stdout else res.stderr
        return jsonify({"help": output, "success": True})
    except subprocess.TimeoutExpired:
        return jsonify({"error": "Command timed out", "success": False})
    except Exception as e:
        return jsonify({"error": str(e), "success": False}), 500

@app.route('/system/update/python', methods=['POST'])
def system_update_python():
    """Update Python dependencies."""
    try:
        subprocess.Popen([sys.executable, "-m", "pip", "install", "--upgrade", "-r", "requirements.txt"], 
                         cwd=Path.cwd(), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return jsonify({"success": True, "message": "Pip upgrade initiated in background."})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/project/rollback', methods=['POST'])
def project_rollback():
    """Restores a previous inventory state. Sanitizes input to prevent path traversal."""
    snapshot_name = request.json.get("name")
    if not snapshot_name: return jsonify({"error": "Snapshot name required"}), 400
    
    # Path Traversal Guard: Ensure name is just a filename
    safe_name = os.path.basename(snapshot_name)
    snapshot_path = pm.app_data_dir / "snapshots" / safe_name
    
    if not snapshot_path.exists(): return jsonify({"error": "Snapshot not found"}), 404
    try:
        import shutil
        pm.save_snapshot() # Save current state before rollback
        shutil.copy2(snapshot_path, pm.inventory_path)
        if session_logger:
            session_logger.log("COMMAND", f"System Rollback: {snapshot_name}", suggestion="System state restored to previous snapshot.")
        return jsonify({"success": True})
    except Exception as e:
        if session_logger:
            session_logger.log("ERROR", f"Rollback failed: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/nexus/projects', methods=['GET', 'POST'])
def nexus_projects():
    if request.method == 'POST':
        p_id = request.json.get("id")
        path = request.json.get("path")
        if not path: return jsonify({"error": "Path required"}), 400
        pm.set_project(path, p_id)
        return jsonify({"success": True, "active_id": p_id})
    return jsonify(pm.get_projects())

@app.route('/project/snapshot', methods=['POST'])
def project_snapshot():
    """Manually triggers a state snapshot."""
    try:
        pm.save_snapshot()
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/export/logs', methods=['GET'])
def export_logs():
    import csv, io
    from flask import Response
    if not pm.log_path.exists(): return jsonify({"error": "No logs found"}), 404
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(["Timestamp", "Level", "Message", "Suggestion"])
    with open(pm.log_path, "r") as f:
        for line in f:
            try:
                log = json.loads(line)
                writer.writerow([datetime.datetime.fromtimestamp(log.get("timestamp", 0)).isoformat(), log.get("level"), log.get("message"), log.get("suggestion", "")])
            except: continue
    return Response(output.getvalue(), mimetype="text/csv", headers={"Content-disposition": "attachment; filename=nexus_history.csv"})

@app.route('/system/uninstall', methods=['POST'])
def system_uninstall():
    try:
        uninstaller = NEXUS_HOME.parent / "repo-mcp-packager" / "uninstall.py"
        if not uninstaller.exists(): return jsonify({"error": "Uninstaller not found"}), 404
        if session_logger:
            session_logger.log("COMMAND", "Factory Reset Initiated", suggestion="Purging all suite data and settings.")
        result = subprocess.run([sys.executable, str(uninstaller), "--yes", "--purge-data", "--kill-venv"], capture_output=True, text=True, timeout=60)
        return jsonify({"success": result.returncode == 0, "stdout": result.stdout, "stderr": result.stderr})
    except Exception as e:
        if session_logger:
            session_logger.log("ERROR", f"Uninstall failure: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/server/control', methods=['POST'])
def server_control():
    s_id = request.json.get("id")
    action = request.json.get("action")
    inv = pm.get_inventory()
    target = next((s for s in inv.get("servers", []) if s.get("id") == s_id), None)
    if not target: return jsonify({"error": "Server not found"}), 404

    cmd = target.get("run", {}).get("start_cmd" if action == "start" else "stop_cmd")
    if not cmd: return jsonify({"error": f"No {action} command defined"}), 400

    try:
        # For now, simplistic start/stop
        subprocess.Popen(shlex.split(cmd), start_new_session=True)
        if session_logger:
            session_logger.log("COMMAND", f"Server {s_id}: {action}", suggestion=f"Triggered: {cmd}")
        return jsonify({"success": True})
    except Exception as e:
        if session_logger:
            session_logger.log("ERROR", f"Control failed for {s_id}: {str(e)}")
        return jsonify({"error": str(e)}), 500

# Server Management endpoints (passing through PM paths)
@app.route('/server/add', methods=['POST'])
def add_server():
    import yaml
    new_server = request.json
    if not new_server.get("id"): return jsonify({"error": "ID required"}), 400
    try:
        pm.save_snapshot()
        inv = {"servers": []}
        if pm.inventory_path.exists():
            with open(pm.inventory_path, "r") as f: inv = yaml.safe_load(f) or {"servers": []}
        if any(s.get("id") == new_server["id"] for s in inv["servers"]): return jsonify({"error": "ID already exists"}), 400
        inv["servers"].append(new_server)
        with open(pm.inventory_path, "w") as f: yaml.dump(inv, f)
        if session_logger:
            session_logger.log("COMMAND", f"Added new server to inventory: {new_server.get('id')}", suggestion="Server is now available in the Dashboard.")
        return jsonify({"success": True})
    except Exception as e:
        if session_logger:
            session_logger.log("ERROR", f"Failed to add server: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/server/delete', methods=['POST'])
def delete_server():
    import yaml
    s_id = request.json.get("id")
    
    # Core Protection Guard
    core_ids = ["mcp-injector", "mcp-server-manager", "repo-mcp-packager", "nexus-librarian"]
    if s_id in core_ids:
        if session_logger:
            session_logger.log("WARNING", f"Blocked deletion attempt of core component: {s_id}", suggestion="Use 'Purge Entire Suite' in Lifecycle for full removal.")
        return jsonify({"error": f"Cannot delete core component '{s_id}'. Use Lifecycle > Purge for full uninstallation."}), 403

    if not pm.inventory_path.exists(): return jsonify({"error": "Inventory not found"}), 404
    try:
        pm.save_snapshot()
        with open(pm.inventory_path, "r") as f: inv = yaml.safe_load(f)
        before_count = len(inv.get("servers", []))
        inv["servers"] = [s for s in inv.get("servers", []) if s.get("id") != s_id]
        after_count = len(inv["servers"])
        
        if before_count == after_count:
            return jsonify({"error": "Server ID not found"}), 404

        with open(pm.inventory_path, "w") as f: yaml.dump(inv, f)
        if session_logger:
            session_logger.log("COMMAND", f"Deleted server: {s_id}", suggestion="Inventory updated.")
        return jsonify({"success": True})
    except Exception as e:
        if session_logger:
            session_logger.log("ERROR", f"Failed to delete server {s_id}: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/librarian/resource/delete', methods=['POST'])
def delete_link():
    link_id = request.json.get("id")
    db_path = pm.app_data_dir / "knowledge.db"
    if not db_path.exists(): return jsonify({"error": "DB not found"}), 404
    try:
        conn = sqlite3.connect(db_path)
        conn.execute("DELETE FROM links WHERE id = ?", (link_id,))
        conn.commit()
        conn.close()
        if session_logger:
            session_logger.log("COMMAND", f"Deleted Librarian resource ID: {link_id}", suggestion="Librarian index updated.")
        return jsonify({"success": True})
    except Exception as e:
        if session_logger:
            session_logger.log("ERROR", f"Failed to delete Librarian resource: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/librarian/resource/open', methods=['POST'])
def open_resource():
    link_id = request.json.get("id")
    root = Path(__file__).parent.parent
    librarian_script = root / "mcp-link-library" / "mcp.py"
    if not librarian_script.exists():
         return jsonify({"error": "Librarian script not found"}), 500
    
    try:
        # Run mcp.py --open <id>
        subprocess.Popen([sys.executable, str(librarian_script), "--open", str(link_id)])
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/librarian/resource/edit', methods=['POST'])
def edit_resource():
    link_id = request.json.get("id")
    root = Path(__file__).parent.parent
    librarian_script = root / "mcp-link-library" / "mcp.py"
    if not librarian_script.exists():
         return jsonify({"error": "Librarian script not found"}), 500
    
    try:
        # Run mcp.py --edit <id>
        subprocess.Popen([sys.executable, str(librarian_script), "--edit", str(link_id)])
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/librarian/roots', methods=['GET', 'POST', 'DELETE'])
def librarian_roots():
    db_path = pm.app_data_dir / "knowledge.db"
    try:
        conn = sqlite3.connect(db_path)
        if request.method == 'POST':
            path = request.json.get("path")
            conn.execute("INSERT OR IGNORE INTO scan_roots (path) VALUES (?)", (path,))
            conn.commit()
            if session_logger:
                session_logger.log("COMMAND", f"Added scan root: {path}")
            return jsonify({"success": True})
        elif request.method == 'DELETE':
            root_id = request.args.get("id")
            conn.execute("DELETE FROM scan_roots WHERE id = ?", (root_id,))
            conn.commit()
            if session_logger:
                session_logger.log("COMMAND", f"Removed scan root ID: {root_id}")
            return jsonify({"success": True})
        
        rows = conn.execute("SELECT id, path, created_at FROM scan_roots").fetchall()
        conn.close()
        return jsonify([{"id": r[0], "path": r[1], "created_at": r[2]} for r in rows])
    except Exception as e: return jsonify({"error": str(e)}), 500

@app.route('/librarian/watcher', methods=['GET', 'POST'])
def librarian_watcher():
    if request.method == 'POST':
        action = request.json.get("action")
        if action == 'start':
            if pm.watcher_proc and pm.watcher_proc.poll() is None:
                return jsonify({"status": "already running"})
            
            bin_path = NEXUS_HOME.parent / "mcp-link-library" / "mcp.py"
            pm.watcher_proc = subprocess.Popen([sys.executable, str(bin_path), "--watch"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            return jsonify({"status": "starting", "pid": pm.watcher_proc.pid})
        elif action == 'stop':
            if pm.watcher_proc:
                pm.watcher_proc.terminate()
                pm.watcher_proc = None
            # Aggressive kill without shell=True for security
            import psutil
            for p in psutil.process_iter(['cmdline']):
                if "mcp.py --watch" in " ".join(p.info['cmdline'] or []):
                    try: p.kill()
                    except: pass
            return jsonify({"status": "stopped"})
            
    is_alive = pm.watcher_proc is not None and pm.watcher_proc.poll() is None
    if not is_alive:
        # Check system proc list just in case
        import psutil
        for p in psutil.process_iter(['cmdline']):
            if "mcp.py --watch" in " ".join(p.info['cmdline'] or []):
                is_alive = True
                break
                
    return jsonify({"status": "online" if is_alive else "offline"})

@app.route('/librarian/links', methods=['GET'])
def get_links():
    db_path = pm.app_data_dir / "knowledge.db"
    if not db_path.exists(): return jsonify([])
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        rows = conn.execute("SELECT id, url, title, categories, description, domain, created_at FROM links ORDER BY id DESC").fetchall()
        conn.close()
        return jsonify([dict(r) for r in rows])
    except Exception as e: return jsonify({"error": str(e)}), 500

@app.route('/artifacts', methods=['GET'])
@app.route('/artifact/list', methods=['GET'])  # v16 alias — resolves 404 gap
def get_artifacts():
    artifact_dir = pm.app_data_dir / "artifacts"
    if not artifact_dir.exists(): return jsonify([])
    results = []
    try:
        for f in sorted(artifact_dir.glob("*"), key=os.path.getmtime, reverse=True)[:50]:
            results.append({"name": f.name, "path": str(f), "size": f.stat().st_size, "modified": os.path.getmtime(f)})
    except: pass
    return jsonify(results)


import threading
import uuid

class ForgeManager:
    """Manages asynchronous Forge tasks.

    Thread safety: self._lock must be held for all reads/writes of self.tasks
    because start_task (HTTP thread) and _run_forge (background thread)
    both mutate the dict concurrently.
    """
    MAX_TASKS = 50  # Evict oldest terminal tasks beyond this cap

    def __init__(self):
        self.tasks = {}
        self._lock = threading.Lock()  # Guards all self.tasks mutations

    def _evict(self):
        """Remove oldest completed/failed tasks when cap is exceeded. Caller must hold self._lock."""
        if len(self.tasks) < self.MAX_TASKS:
            return
        terminal = [
            (tid, t) for tid, t in self.tasks.items()
            if t["status"] in ("completed", "failed")
        ]
        # Sort by start_time ascending and drop oldest half to stay under cap
        terminal.sort(key=lambda x: x[1].get("start_time", 0))
        for tid, _ in terminal[: len(terminal) // 2 + 1]:
            del self.tasks[tid]

    def start_task(self, source, name=None):
        """Register a new forge task and return its ID. Thread-safe."""
        with self._lock:
            self._evict()
            task_id = str(uuid.uuid4())
            self.tasks[task_id] = {
                "id": task_id,
                "status": "pending",
                "source": source,
                "logs": [],
                "result": None,
                "start_time": time.time()
            }
        thread = threading.Thread(target=self._run_forge, args=(task_id, source, name))
        thread.daemon = True
        thread.start()
        return task_id

    def _run_forge(self, task_id, source, name):
        task = self.tasks[task_id]
        task["status"] = "running"
        try:
            import sys, io as _io
            project_root = Path(__file__).parent
            if str(project_root / "forge") not in sys.path:
                sys.path.insert(0, str(project_root / "forge"))

            from forge_engine import ForgeEngine

            engine = ForgeEngine(pm.app_data_dir.parent, inventory_path=pm.inventory_path)

            task["logs"].append(f"Starting Forge for: {source}")
            task["logs"].append(f"Target Inventory: {pm.inventory_path}")

            # Redirect stdout so ForgeEngine's print() lines flow into task logs
            class _LogCapture(_io.TextIOBase):
                def write(self_inner, s):
                    if s.strip():
                        task["logs"].append(s.rstrip())
                    return len(s)
                def flush(self_inner): pass

            _orig_stdout = sys.stdout
            sys.stdout = _LogCapture()
            try:
                target_path = engine.forge(source, name)
            finally:
                sys.stdout = _orig_stdout  # always restore

            task["logs"].append(f"Server available at: {target_path}")
            task["status"] = "completed"
            task["result"] = {
                "success": True,
                "stdout": "\n".join(task["logs"]),
                "server_path": str(target_path)
            }

            if session_logger:
                session_logger.log_command(f"FORGE: {source}", "SUCCESS", result=str(target_path))
            
            # Persist for recovery in GUI
            pm.last_forge_result = task["result"]
            pm.save_context()

        except Exception as e:
            sys.stdout = _orig_stdout if '_orig_stdout' in dir() else sys.stdout
            task["status"] = "failed"
            task["logs"].append(f"ERROR: {str(e)}")
            import traceback
            task["logs"].append(traceback.format_exc())
            task["result"] = {"success": False, "error": str(e)}
            if session_logger:
                session_logger.log("ERROR", f"Forge failed: {str(e)}")

fm = ForgeManager()

@app.route('/forge', methods=['POST'])
def forge_server():
    """Triggers the Nexus Forge Engine asynchronously."""
    source = request.json.get("source")
    name = request.json.get("name")
    if not source: return jsonify({"error": "Source path or URL required"}), 400
    
    task_id = fm.start_task(source, name)
    
    if session_logger:
        session_logger.log("COMMAND", f"Forge Initiated (Async): {source}", suggestion="Check Progress tab for status.")

    return jsonify({"success": True, "task_id": task_id})

@app.route('/forge/status/<task_id>', methods=['GET'])
def forge_status(task_id):
    task = fm.tasks.get(task_id)
    if not task: return jsonify({"error": "Task not found"}), 404
    return jsonify(task)

@app.route('/forge/last', methods=['GET'])
def forge_last():
    """Returns the last persisted forge result."""
    return jsonify(pm.last_forge_result or {})

if __name__ == '__main__':
    # ── Do not run gui_bridge.py directly ──────────────────────────────────
    # The canonical entry point is nexus_tray.py, which starts Flask in a
    # daemon thread and provides a macOS/Windows system-tray icon.
    # Double-click "Start Nexus.command" on your Desktop instead.
    #
    # This fallback exists for CI / headless environments only.
    import os
    if os.environ.get("NEXUS_HEADLESS") == "1":
        print(f"🚀 Nexus GUI Bridge (headless) — port 5001")
        app.run(host='127.0.0.1', port=5001, debug=False)
    else:
        print("⚠️  Use  'python3 nexus_tray.py'  or double-click 'Start Nexus.command' on your Desktop.")
        print("   Set NEXUS_HEADLESS=1 to force terminal mode (CI/servers only).")

